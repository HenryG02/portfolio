{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccCjeU6UDQaO"
      },
      "source": [
        "This project aims to train a deep learning model that can correctly recognize and classify handwritten digits from 0 to 9, using the MNIST dataset. To add upon this simpler task, we'll import handwritten digits images that I myself have drown to verify if the model can correctly identify which digit is written in each of them"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing and loading the dataset"
      ],
      "metadata": {
        "id": "s-UkmfwxGiwf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pcu98G8TbFor"
      },
      "outputs": [],
      "source": [
        "# Importing necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAvj2XPbbS-g",
        "outputId": "35d4ed72-a4dc-4c8a-aeaa-1088ebb34ace"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Loading MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "j3yswJiiEJM6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40d10c67-1b9b-48d1-80c7-0ce9249fa987"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28) <class 'numpy.ndarray'>\n",
            "(60000,) <class 'numpy.ndarray'>\n",
            "(10000, 28, 28) <class 'numpy.ndarray'>\n",
            "(10000,) <class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "# Understanding how the dataset was imported\n",
        "for i in [x_train, y_train, x_test, y_test]:\n",
        "    print(i.shape, type(i))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeDjcBE5cSFc"
      },
      "source": [
        "From the output above, we identify that there are 60,000 images in the training set and 10,000 in the testing set, each of them having 28x28 pixels. All the data is stored in numpy arrays"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WdU8By52cni9"
      },
      "outputs": [],
      "source": [
        "# Normalizing data (0 to 1)\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Network architecture, training and evaluation"
      ],
      "metadata": {
        "id": "avV0ykGgGp3s"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chwCGkvjdJU_"
      },
      "source": [
        "We'll first train a simple neural network with some hidden layers and see how it performs both on the testing set and on the images I took of my own handwritten digits. After that, we'll train a convolutional neural network (CNN), which is known for being great at image recognition and classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xm139sRIdVeL"
      },
      "outputs": [],
      "source": [
        "# Flattening data (for the simpler neural network)\n",
        "x_train_flat = x_train.reshape(60000, 784)\n",
        "x_test_flat = x_test.reshape(10000, 784)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZO2_VJSKdmsF"
      },
      "outputs": [],
      "source": [
        "# Building model architecture\n",
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Dense(500, activation='relu', input_shape=(784,)))\n",
        "model.add(keras.layers.Dropout(0.2))\n",
        "model.add(keras.layers.Dense(200, activation='relu'))\n",
        "model.add(keras.layers.Dropout(0.2))\n",
        "model.add(keras.layers.Dense(100, activation='relu'))\n",
        "model.add(keras.layers.Dropout(0.1))\n",
        "model.add(keras.layers.Dense(10, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hr6S-rITd6td"
      },
      "outputs": [],
      "source": [
        "# Compiling model\n",
        "model.compile(optimizer='Adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gILCm0QPeHLT"
      },
      "outputs": [],
      "source": [
        "# Training the model\n",
        "model.fit(x_train_flat, y_train, epochs=3, validation_split=0.2, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5QOdb-AEeXpo"
      },
      "outputs": [],
      "source": [
        "# Evaluating model performance on test set\n",
        "test_loss, test_accuracy = model.evaluate(x_test_flat, y_test)\n",
        "print(test_loss, test_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Network performance on my own handwritten digits"
      ],
      "metadata": {
        "id": "grtdB0YhG3K8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmCECZZjfPqy"
      },
      "source": [
        "Now, we'll see if the model can correctly classify my own handwritten number!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZFs1xStfWZr"
      },
      "outputs": [],
      "source": [
        "# Loading image of a 1\n",
        "img = Image.open('/content/drive/MyDrive/Model Testing - 1.png')\n",
        "img_grey = img.convert('L')\n",
        "length, height = img_grey.size\n",
        "pixels = img_grey.load()\n",
        "for i in range(length):\n",
        "    for j in range(height):\n",
        "        pixels[i, j] = 255 - pixels[i, j]\n",
        "img_grey = img_grey.resize((28, 28))\n",
        "img_array = np.array(img_grey)\n",
        "img_array = img_array / 255.0\n",
        "img_flat = img_array.reshape(1, 784)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2GTMkkXUAGQC"
      },
      "outputs": [],
      "source": [
        "# Loading image of a 4\n",
        "img_4 = Image.open('/content/drive/MyDrive/Model Testing - 4.png')\n",
        "img_4_grey = img_4.convert('L')\n",
        "length_4, height_4 = img_4_grey.size\n",
        "pixels = img_4_grey.load()\n",
        "for i in range(length_4):\n",
        "    for j in range(height_4):\n",
        "        pixels[i, j] = 255 - pixels[i, j]\n",
        "img_4_grey = img_4_grey.resize((28, 28))\n",
        "img_4_array = np.array(img_4_grey)\n",
        "img_4_array = img_4_array / 255.0\n",
        "img_4_flat = img_4_array.reshape(1, 784)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ikry6lyWhaJS"
      },
      "outputs": [],
      "source": [
        "# Testing\n",
        "prediction = model.predict(img_flat)\n",
        "predicted_class = np.argmax(prediction)\n",
        "print('A imagem é provavelmente o número: ', predicted_class)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LA2uz_sqtNc0"
      },
      "source": [
        "We rapidly identify that our simple neural network is not predicting my handwritten digits very well :(\n",
        "\n",
        "To improve on this, we'll create a convulational neural network, which is notoriously known for its great performance on image-related tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convolutional Neural Network (CNN) architecture, training and evaluation"
      ],
      "metadata": {
        "id": "3Mdf5A_2HmhL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLC3b0XatgjK",
        "outputId": "3f5c1aa0-c5a3-4331-ec34-34eea2e8bed5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "# CNN design and architecture\n",
        "cnn_model = keras.Sequential()\n",
        "cnn_model.add(keras.layers.Conv2D(28, kernel_size=(2,2), activation='relu', input_shape=(28, 28, 1)))\n",
        "cnn_model.add(keras.layers.MaxPool2D())\n",
        "cnn_model.add(keras.layers.Dropout(0.3))\n",
        "cnn_model.add(keras.layers.Conv2D(56, kernel_size=(2,2), activation='relu'))\n",
        "cnn_model.add(keras.layers.MaxPool2D())\n",
        "cnn_model.add(keras.layers.Flatten())\n",
        "cnn_model.add(keras.layers.Dense(56, activation='relu'))\n",
        "cnn_model.add(keras.layers.Dropout(0.2))\n",
        "cnn_model.add(keras.layers.Dense(10, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pztFweSQuzJx"
      },
      "outputs": [],
      "source": [
        "# Compiling CNN\n",
        "cnn_model.compile(optimizer='adam',\n",
        "               loss='sparse_categorical_crossentropy',\n",
        "               metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZKLb7NwvEen",
        "outputId": "8878dfff-c1cf-456b-8844-521fe0e8e49f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 24ms/step - accuracy: 0.8027 - loss: 0.6160 - val_accuracy: 0.9693 - val_loss: 0.1026\n",
            "Epoch 2/3\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 24ms/step - accuracy: 0.9564 - loss: 0.1377 - val_accuracy: 0.9770 - val_loss: 0.0766\n",
            "Epoch 3/3\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 25ms/step - accuracy: 0.9679 - loss: 0.1005 - val_accuracy: 0.9827 - val_loss: 0.0564\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c5ffaf63130>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "# Training CNN\n",
        "cnn_model.fit(x_train, y_train, epochs=3, validation_split=0.2, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GxzuyCiwHkU",
        "outputId": "a9d9a37d-cf78-4e9b-fd31-1a6fc8c3fd46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9781 - loss: 0.0629\n",
            "0.05135170742869377 0.9829000234603882\n"
          ]
        }
      ],
      "source": [
        "# Evaluating CNN performance on test set\n",
        "cnn_test_loss, cnn_test_accuracy = cnn_model.evaluate(x_test, y_test)\n",
        "print(cnn_test_loss, cnn_test_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xc9t5olSwbIu",
        "outputId": "7a2ced1b-e9be-4081-c51c-b6fdb8c07958"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "A imagem é provavelmente o número:  0\n"
          ]
        }
      ],
      "source": [
        "# The greatest task: correctly identifying my own handwritten digits\n",
        "cnn_prediction = cnn_model.predict(tf.expand_dims(img_array, axis=0))\n",
        "cnn_predicted_class = np.argmax(cnn_prediction)\n",
        "print('A imagem é provavelmente o número: ', cnn_predicted_class)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The CNN model **correctly** identified my own handwritten digits!!!\n",
        "\n",
        "Notice that the choices I made on the number of hidden layers, rates of dropout and other parameters were made based on trial and error and by identifying where the issues could possibly be (overfitting, lack of complexity of the model...)"
      ],
      "metadata": {
        "id": "nK0x-bpzM3Vk"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1WOsYO8Lk4P736w3d_uEMJ_a4PmUG61E0",
      "authorship_tag": "ABX9TyNRu2n+VuVScS/mwVW8BehV"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}